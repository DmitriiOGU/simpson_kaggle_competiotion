{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Подготовка к исполнению\n",
    "### Обучение производилось с помощью kernel Kaggle, а не google collaboratory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "import PIL\n",
    "print(PIL.PILLOW_VERSION)\n",
    "\n",
    "#file paths\n",
    "#/kaggle/input/simpsons4/train\n",
    "#/kaggle/input/simpsons4/testset/testset\n",
    "\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "\n",
    "if not train_on_gpu:\n",
    "    print('CUDA is not available.  Training on CPU ...')\n",
    "else:\n",
    "    print('CUDA is available!  Training on GPU ...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from skimage import io\n",
    "import random\n",
    "\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "\n",
    "from torchvision import transforms\n",
    "from multiprocessing.pool import ThreadPool\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "\n",
    "from matplotlib import colors, pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_MODES = ['train', 'val', 'test']\n",
    "RESCALE_SIZE = 224\n",
    "DEVICE = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Построение обучающей выборки\n",
    "### Выборка была расширена до 100 единиц по каждому классу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR = Path('/kaggle/input/simpsons4/train')\n",
    "TEST_DIR = Path('/kaggle/input/simpsons4/testset/testset')\n",
    "KOLICHESTVO_NA_CLASS=100\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "train_val_files= sorted(list(TRAIN_DIR.rglob('*.jpg')))\n",
    "test_files = sorted(list(TEST_DIR.rglob('*.jpg')))\n",
    "\n",
    "name_list=[]\n",
    "for i in train_val_files:\n",
    "    namepers=str(i)[47:].index('/')\n",
    "    name_list.append(str(i)[47:][:namepers])\n",
    "name_list_np=np.array(name_list)\n",
    "name_list_pd=pd.Series(name_list_np)\n",
    "kolichestvo_pd=name_list_pd.value_counts().where(name_list_pd.value_counts()<KOLICHESTVO_NA_CLASS).dropna()\n",
    "names=kolichestvo_pd.index.tolist()\n",
    "kolichestvo_pd=pd.to_numeric(kolichestvo_pd, downcast='signed')\n",
    "special = dict.fromkeys(names)\n",
    "for i in special:\n",
    "    special[i]=[]\n",
    "for i in train_val_files:\n",
    "    namepers=str(i)[47:].index('/')\n",
    "    name=(str(i)[47:][:namepers])\n",
    "    if name in special.keys():\n",
    "        special[name].append(i)\n",
    "for i in special:\n",
    "    if len(special[i]) < KOLICHESTVO_NA_CLASS:\n",
    "        special[i] = special[i] * (KOLICHESTVO_NA_CLASS // len(special[i]))\n",
    "        special[i].extend(special[i][:100 - len(special[i])])\n",
    "        special[i]=special[i][:100-kolichestvo_pd[i]]\n",
    "for i in special:\n",
    "    train_val_files.extend(special[i])\n",
    "train_val_files=sorted(train_val_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpsonsDataset(Dataset):\n",
    "  def __init__(self, files, mode, augmentations = None):\n",
    "    super().__init__()\n",
    "    self.files = files\n",
    "    self.mode = mode\n",
    "    self.augmentations = augmentations\n",
    "\n",
    "    if self.mode not in DATA_MODES:\n",
    "      print(f'wrong mode: {self.mode}')\n",
    "      raise NameError\n",
    "\n",
    "    self.len_ = len(self.files)\n",
    "    self.label_encoder = LabelEncoder()\n",
    "\n",
    "    if self.mode != 'test':\n",
    "      self.labels = [path.parent.name for path in self.files]\n",
    "      self.label_encoder.fit(self.labels)\n",
    "\n",
    "      with open('label_encoder.pkl', 'wb') as le_dump:\n",
    "        pickle.dump(self.label_encoder, le_dump)\n",
    "\n",
    "  def __len__(self):\n",
    "    return self.len_\n",
    "\n",
    "  def load_sample(self, file):\n",
    "    image = Image.open(file)\n",
    "    image.load()\n",
    "    return image\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    transform = transforms.Compose([\n",
    "      transforms.ToTensor(),\n",
    "      transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])                                \n",
    "    ])\n",
    "    augmentations_pipeline= A.Compose([\n",
    "        A.HorizontalFlip(p = 0.5), # apply horizontal flip to 50% of images\n",
    "        A.OneOf([\n",
    "                # apply one of transforms to 50% of images\n",
    "                A.ToGray(),\n",
    "                A.RandomContrast(), # apply random contrast\n",
    "                A.RandomGamma(), # apply random gamma\n",
    "                A.RandomBrightness(), # apply random brightness\n",
    "            ],p = 0.5),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225]),    \n",
    "        ToTensor() # convert the image to PyTorch tensor\n",
    "    ],\n",
    "    p = 1)\n",
    "    x = self.load_sample(self.files[index])\n",
    "    x = self._prepare_sample(x)\n",
    "    if self.mode == 'test':\n",
    "        return transform(x)\n",
    "    else:\n",
    "      x = augmentations_pipeline(image = x)['image']\n",
    "      label = self.labels[index]\n",
    "      label_id = self.label_encoder.transform([label])\n",
    "      y = label_id.item()\n",
    "      return x, y\n",
    "\n",
    "  def _prepare_sample(self, image):\n",
    "    image = image.resize((RESCALE_SIZE, RESCALE_SIZE))\n",
    "    return np.array(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разбиение на train и validation части"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_val_labels = [path.parent.name for path in train_val_files]\n",
    "train_files, val_files = train_test_split(train_val_files, test_size=0.3, \\\n",
    "                                          stratify=train_val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = SimpsonsDataset(val_files, mode='val')\n",
    "train_dataset = SimpsonsDataset(train_files, mode='train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Визуализация нескольких экземпляров из выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img, title=None, plt_ax=plt, default=False):\n",
    "  img = img.numpy().transpose((1, 2, 0))\n",
    "  mean = np.array([0.485, 0.456, 0.406])\n",
    "  std = np.array([0.229, 0.224, 0.225])\n",
    "  img = std * img + mean\n",
    "  img = np.clip(img, 0, 1)\n",
    "  plt_ax.imshow(img)\n",
    "  if title is not None:\n",
    "    plt_ax.set_title(title)\n",
    "  plt_ax.grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=3, ncols=3, figsize=(10,10), sharex=True, sharey=True)\n",
    "\n",
    "for fig_x in ax.flatten():\n",
    "    random_characters = int(np.random.uniform(0,1000))\n",
    "    im_val, label = val_dataset[random_characters]\n",
    "    img_label = \" \".join(map(lambda x: x.capitalize(),\\\n",
    "                val_dataset.label_encoder.inverse_transform([label])[0].split('_')))\n",
    "    imshow(im_val.data.cpu(), \\\n",
    "          title=img_label,plt_ax=fig_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание функций обучения нейронной сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_epoch(model, train_loader, criterion, optimizer):\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    processed_data = 0\n",
    "  \n",
    "    for inputs, labels in train_loader:\n",
    "        inputs = inputs.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        preds = torch.argmax(outputs, 1)\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "        processed_data += inputs.size(0)\n",
    "              \n",
    "    train_loss = running_loss / processed_data\n",
    "    train_acc = running_corrects.cpu().numpy() / processed_data\n",
    "    return train_loss, train_acc\n",
    "  \n",
    "def eval_epoch(model, val_loader, criterion):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    processed_size = 0\n",
    "\n",
    "    for inputs, labels in val_loader:\n",
    "        inputs = inputs.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "\n",
    "        with torch.set_grad_enabled(False):\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            preds = torch.argmax(outputs, 1)\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "        processed_size += inputs.size(0)\n",
    "    val_loss = running_loss / processed_size\n",
    "    val_acc = running_corrects.double() / processed_size\n",
    "    return val_loss, val_acc\n",
    "  \n",
    "def train(train_files, val_files, model, epochs, batch_size):\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    history = []\n",
    "    log_template = \"\\nEpoch {ep:03d} train_loss: {t_loss:0.4f} \\\n",
    "    val_loss {v_loss:0.4f} train_acc {t_acc:0.4f} val_acc {v_acc:0.4f}\"\n",
    "\n",
    "    with tqdm(desc=\"epoch\", total=epochs) as pbar_outer:\n",
    "      \n",
    "        \n",
    "        opt = torch.optim.AdamW(model.parameters(),amsgrad=True)\n",
    "\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            train_loss, train_acc = fit_epoch(model, train_loader, criterion, opt)\n",
    "            print(\"loss\", train_loss)\n",
    "            \n",
    "            val_loss, val_acc = eval_epoch(model, val_loader, criterion)\n",
    "            history.append((train_loss, train_acc, val_loss, val_acc))\n",
    "            \n",
    "            pbar_outer.update(1)\n",
    "            tqdm.write(log_template.format(ep=epoch+1, t_loss=train_loss,\\\n",
    "                                           v_loss=val_loss, t_acc=train_acc, v_acc=val_acc))\n",
    "            \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, test_loader):\n",
    "    with torch.no_grad():\n",
    "        logits = []\n",
    "    \n",
    "        for inputs in test_loader:\n",
    "            inputs = inputs.to(DEVICE)\n",
    "            model.eval()\n",
    "            outputs = model(inputs).cpu()\n",
    "            logits.append(outputs)\n",
    "            \n",
    "    probs = nn.functional.softmax(torch.cat(logits), dim=-1).numpy()\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание модели и обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "n_classes = len(np.unique(train_val_labels))\n",
    "model = models.resnet34(pretrained=True).to(DEVICE)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, n_classes)\n",
    "model.train()\n",
    "model = model.to(DEVICE)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = train(train_dataset, val_dataset, model=model, epochs=30, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc, val_loss, val_acc = zip(*history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 9))\n",
    "plt.plot(loss, label=\"train_loss\")\n",
    "plt.plot(val_loss, label=\"val_loss\")\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Подготовка данных для отправки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = pickle.load(open(\"label_encoder.pkl\", 'rb'))\n",
    "\n",
    "test_dataset = SimpsonsDataset(test_files, mode=\"test\")\n",
    "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=64)\n",
    "probs = predict(model, test_loader)\n",
    "\n",
    "preds = label_encoder.inverse_transform(np.argmax(probs, axis=1))\n",
    "test_filenames = [path.name for path in test_dataset.files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.DataFrame({'Id': test_filenames, 'Expected': preds})\n",
    "submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv('submission_resnet34_aug.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
